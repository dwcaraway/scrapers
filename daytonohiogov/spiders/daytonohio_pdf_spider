__author__ = 'dwcaraway'

from scrapy.spider import BaseSpider
from scrapy.selector import Selector
from scrapy.http import Request
import urlparse
import re
import urllib2
import lxml
import datetime
from daytonohiogov.items import DaytonOhioPDFItem
import phonenumbers

facebook_matcher = re.compile('.*GoHere=(.*facebook.*)')
twitter_matcher = re.compile('.*GoHere=(.*twitter.*)')
category_matcher = re.compile('.*[.]com/(.*)[.]asp')

class DaytonOhioPDFSpider(BaseSpider):
    """Crawls daytonohio.gov looking for PDF documents"""

    template_url = 'http://daytonohio.gov/Search/_layouts/srchrss.aspx?k=pdf&start=%d'

    name = "daytonohio_pdf"
    allowed_domains = ["daytonohio.gov"]
    start_urls = [
        template_url % 1
    ]

    def parse(self, response):
        sel = Selector(response)
        items = sel.xpath('//item')

        results = []

        for item in items:
            title = item.xpath('title/text()').extract()[0]
            url = item.xpath('link/text()').extract()[0]
            author = item.xpath('author/text()').extract()[0]
            pubDate = item.xpath('pubDate/text()').extract()[0]

            print "%s, %s, %s, %s" % (title, url, author, pubDate)

            results.append(DaytonOhioPDFItem(title=title, url=url, author=author, pubDate=pubDate))

        # if items:
        #     query_args = urlparse.parse_qs(urlparse.urlparse(response.url).query)
        #     current = int(query_args['start'][0])
        #     new_url = self.template_url % (current + len(items))
        #     results.append(Request(url=new_url, callback=self.parse))

        return results

if __name__ == '__main__':
    #Run data extraction test on individual page
    urls = ["http://daytonohio.gov/Search/_layouts/srchrss.aspx?k=pdf&start=1"]
    import requests
    from scrapy.http import Request, HtmlResponse

    for url in urls:
        request = Request(url=url)
        response = HtmlResponse(url=url, request=request, body=requests.get(url).text, encoding='utf-8')

        print DaytonOhioPDFSpider.parse(DaytonOhioPDFSpider(), response=response)

